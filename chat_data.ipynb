{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q langchain\n",
    "! pip install -q pypdf\n",
    "! pip install -q yt_dlp\n",
    "! pip install -q pydub\n",
    "! pip install -q ffmpeg\n",
    "! pip install -q ffprobe\n",
    "! pip install -q chromadb\n",
    "! pip install -q pysqlite3-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latest version of chroma has some issues with sqlite3\n",
    "\n",
    "# these three lines swap the stdlib sqlite3 lib with the pysqlite3 package\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jGwO_UgTS7I\n",
      "[youtube] jGwO_UgTS7I: Downloading webpage\n",
      "[youtube] jGwO_UgTS7I: Downloading ios player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading android player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading m3u8 information\n",
      "[info] jGwO_UgTS7I: Downloading 1 format(s): 140\n",
      "[download] docs/youtube//Stanford CS229ï¼š Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a has already been downloaded\n",
      "[download] 100% of   69.76MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
     ]
    },
    {
     "ename": "DownloadError",
     "evalue": "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPostProcessingError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:3439\u001b[0m, in \u001b[0;36mYoutubeDL.process_info\u001b[0;34m(self, info_dict)\u001b[0m\n\u001b[1;32m   3438\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3439\u001b[0m     replace_info_dict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpost_process(dl_filename, info_dict, files_to_move))\n\u001b[1;32m   3440\u001b[0m \u001b[39mexcept\u001b[39;00m PostProcessingError \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:3621\u001b[0m, in \u001b[0;36mYoutubeDL.post_process\u001b[0;34m(self, filename, info, files_to_move)\u001b[0m\n\u001b[1;32m   3620\u001b[0m info[\u001b[39m'\u001b[39m\u001b[39m__files_to_move\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m files_to_move \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m-> 3621\u001b[0m info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_all_pps(\u001b[39m'\u001b[39;49m\u001b[39mpost_process\u001b[39;49m\u001b[39m'\u001b[39;49m, info, additional_pps\u001b[39m=\u001b[39;49minfo\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39m__postprocessors\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m   3622\u001b[0m info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_pp(MoveFilesAfterDownloadPP(\u001b[39mself\u001b[39m), info)\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:3603\u001b[0m, in \u001b[0;36mYoutubeDL.run_all_pps\u001b[0;34m(self, key, info, additional_pps)\u001b[0m\n\u001b[1;32m   3602\u001b[0m \u001b[39mfor\u001b[39;00m pp \u001b[39min\u001b[39;00m (additional_pps \u001b[39mor\u001b[39;00m []) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pps[key]:\n\u001b[0;32m-> 3603\u001b[0m     info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_pp(pp, info)\n\u001b[1;32m   3604\u001b[0m \u001b[39mreturn\u001b[39;00m info\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:3581\u001b[0m, in \u001b[0;36mYoutubeDL.run_pp\u001b[0;34m(self, pp, infodict)\u001b[0m\n\u001b[1;32m   3580\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3581\u001b[0m     files_to_delete, infodict \u001b[39m=\u001b[39m pp\u001b[39m.\u001b[39;49mrun(infodict)\n\u001b[1;32m   3582\u001b[0m \u001b[39mexcept\u001b[39;00m PostProcessingError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   3583\u001b[0m     \u001b[39m# Must be True and not 'only_download'\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/postprocessor/common.py:24\u001b[0m, in \u001b[0;36mPostProcessorMetaClass.run_wrapper.<locals>.run\u001b[0;34m(self, info, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_progress({\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mstarted\u001b[39m\u001b[39m'\u001b[39m}, info_copy)\n\u001b[0;32m---> 24\u001b[0m ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, info, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/postprocessor/common.py:129\u001b[0m, in \u001b[0;36mPostProcessor._restrict_to.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, info)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m allowed[format_type]:\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, info)\n\u001b[1;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/postprocessor/ffmpeg.py:493\u001b[0m, in \u001b[0;36mFFmpegExtractAudioPP.run\u001b[0;34m(self, information)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[39mreturn\u001b[39;00m [], information\n\u001b[0;32m--> 493\u001b[0m filecodec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_audio_codec(path)\n\u001b[1;32m    494\u001b[0m \u001b[39mif\u001b[39;00m filecodec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/postprocessor/ffmpeg.py:241\u001b[0m, in \u001b[0;36mFFmpegPostProcessor.get_audio_codec\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobe_available \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavailable:\n\u001b[0;32m--> 241\u001b[0m     \u001b[39mraise\u001b[39;00m PostProcessingError(\u001b[39m'\u001b[39m\u001b[39mffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    242\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mPostProcessingError\u001b[0m: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDownloadError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m save_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdocs/youtube/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m loader \u001b[39m=\u001b[39m GenericLoader(\n\u001b[1;32m      4\u001b[0m     YoutubeAudioLoader([url],save_dir),\n\u001b[1;32m      5\u001b[0m     OpenAIWhisperParser()\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m docs \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39;49mload()\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/langchain/document_loaders/generic.py:90\u001b[0m, in \u001b[0;36mGenericLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m     89\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load all documents.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlazy_load())\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/langchain/document_loaders/generic.py:85\u001b[0m, in \u001b[0;36mGenericLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlazy_load\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     83\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Document]:\n\u001b[1;32m     84\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load documents lazily. Use this when working at a large scale.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mfor\u001b[39;00m blob \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblob_loader\u001b[39m.\u001b[39myield_blobs():\n\u001b[1;32m     86\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblob_parser\u001b[39m.\u001b[39mlazy_parse(blob)\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/langchain/document_loaders/blob_loaders/youtube_audio.py:45\u001b[0m, in \u001b[0;36mYoutubeAudioLoader.yield_blobs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murls:\n\u001b[1;32m     43\u001b[0m     \u001b[39m# Download file\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[39mwith\u001b[39;00m yt_dlp\u001b[39m.\u001b[39mYoutubeDL(ydl_opts) \u001b[39mas\u001b[39;00m ydl:\n\u001b[0;32m---> 45\u001b[0m         ydl\u001b[39m.\u001b[39;49mdownload(url)\n\u001b[1;32m     47\u001b[0m \u001b[39m# Yield the written blobs\u001b[39;00m\n\u001b[1;32m     48\u001b[0m loader \u001b[39m=\u001b[39m FileSystemBlobLoader(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir, glob\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*.m4a\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:3485\u001b[0m, in \u001b[0;36mYoutubeDL.download\u001b[0;34m(self, url_list)\u001b[0m\n\u001b[1;32m   3482\u001b[0m     \u001b[39mraise\u001b[39;00m SameFileError(outtmpl)\n\u001b[1;32m   3484\u001b[0m \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m url_list:\n\u001b[0;32m-> 3485\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__download_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_info)(\n\u001b[1;32m   3486\u001b[0m         url, force_generic_extractor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mforce_generic_extractor\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m))\n\u001b[1;32m   3488\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_retcode\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:3460\u001b[0m, in \u001b[0;36mYoutubeDL.__download_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3457\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   3458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   3459\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3460\u001b[0m         res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   3461\u001b[0m     \u001b[39mexcept\u001b[39;00m UnavailableVideoError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   3462\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreport_error(e)\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:1549\u001b[0m, in \u001b[0;36mYoutubeDL.extract_info\u001b[0;34m(self, url, download, ie_key, extra_info, process, force_generic_extractor)\u001b[0m\n\u001b[1;32m   1547\u001b[0m             \u001b[39mraise\u001b[39;00m ExistingVideoReached()\n\u001b[1;32m   1548\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1549\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__extract_info(url, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_info_extractor(key), download, extra_info, process)\n\u001b[1;32m   1550\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1551\u001b[0m     extractors_restricted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mallowed_extractors\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, [\u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:1560\u001b[0m, in \u001b[0;36mYoutubeDL._handle_extraction_exceptions.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m   1559\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1560\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1561\u001b[0m     \u001b[39mexcept\u001b[39;00m (DownloadCancelled, LazyList\u001b[39m.\u001b[39mIndexError, PagedList\u001b[39m.\u001b[39mIndexError):\n\u001b[1;32m   1562\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:1709\u001b[0m, in \u001b[0;36mYoutubeDL.__extract_info\u001b[0;34m(self, url, ie, download, extra_info, process)\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[39mif\u001b[39;00m process:\n\u001b[1;32m   1708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_video(ie_result)\n\u001b[0;32m-> 1709\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_ie_result(ie_result, download, extra_info)\n\u001b[1;32m   1710\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1711\u001b[0m     \u001b[39mreturn\u001b[39;00m ie_result\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:1768\u001b[0m, in \u001b[0;36mYoutubeDL.process_ie_result\u001b[0;34m(self, ie_result, download, extra_info)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[39mif\u001b[39;00m result_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvideo\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1767\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_extra_info(ie_result, extra_info)\n\u001b[0;32m-> 1768\u001b[0m     ie_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_video_result(ie_result, download\u001b[39m=\u001b[39;49mdownload)\n\u001b[1;32m   1769\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_pending_errors(ie_result)\n\u001b[1;32m   1770\u001b[0m     additional_urls \u001b[39m=\u001b[39m (ie_result \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39madditional_urls\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:2897\u001b[0m, in \u001b[0;36mYoutubeDL.process_video_result\u001b[0;34m(self, info_dict, download)\u001b[0m\n\u001b[1;32m   2895\u001b[0m downloaded_formats\u001b[39m.\u001b[39mappend(new_info)\n\u001b[1;32m   2896\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2897\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_info(new_info)\n\u001b[1;32m   2898\u001b[0m \u001b[39mexcept\u001b[39;00m MaxDownloadsReached:\n\u001b[1;32m   2899\u001b[0m     max_downloads_reached \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:3441\u001b[0m, in \u001b[0;36mYoutubeDL.process_info\u001b[0;34m(self, info_dict)\u001b[0m\n\u001b[1;32m   3439\u001b[0m     replace_info_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_process(dl_filename, info_dict, files_to_move))\n\u001b[1;32m   3440\u001b[0m \u001b[39mexcept\u001b[39;00m PostProcessingError \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3441\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreport_error(\u001b[39m'\u001b[39;49m\u001b[39mPostprocessing: \u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m'\u001b[39;49m \u001b[39m%\u001b[39;49m \u001b[39mstr\u001b[39;49m(err))\n\u001b[1;32m   3442\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   3443\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:1042\u001b[0m, in \u001b[0;36mYoutubeDL.report_error\u001b[0;34m(self, message, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreport_error\u001b[39m(\u001b[39mself\u001b[39m, message, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1038\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39m    Do the same as trouble, but prefixes the message with 'ERROR:', colored\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39m    in red if stderr is a tty file.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrouble(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_format_err(\u001b[39m\"\u001b[39;49m\u001b[39mERROR:\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m \u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mStyles\u001b[39m.\u001b[39;49mERROR)\u001b[39m}\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m{\u001b[39;49;00mmessage\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/chatbot/chatbot/lib/python3.8/site-packages/yt_dlp/YoutubeDL.py:981\u001b[0m, in \u001b[0;36mYoutubeDL.trouble\u001b[0;34m(self, message, tb, is_error)\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    980\u001b[0m         exc_info \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mraise\u001b[39;00m DownloadError(message, exc_info)\n\u001b[1;32m    982\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_retcode \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mDownloadError\u001b[0m: ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location"
     ]
    }
   ],
   "source": [
    "url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "save_dir=\"docs/youtube/\"\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/37signals-is-you.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "handbook/37signals-is-you.md at master Â· basecamp/handbook Â· GitHub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle navigation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            SignÂ up\n",
      "          \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Product\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Actions\n",
      "        Automate any workflow\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Packages\n",
      "        Host and manage packages\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Security\n",
      "        Find and fix vulnerabilities\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Codesp\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(docs[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mpage_content[\u001b[39m0\u001b[39m:\u001b[39m200\u001b[39m])\n\u001b[1;32m      2\u001b[0m docs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmetadata\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[0:200])\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m n o p q r s t u v w x y z']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ' '\n",
    ")\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\"\n",
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
       " 'have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related.\",\n",
       " 'For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns.',\n",
       " 'Carriage returns are the \"backslash n\" you see embedded in this string.',\n",
       " 'Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"foo bar bazzyfoo\"\n",
    "text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='MachineLearning-Lecture01  \\n', metadata={'source': 'docs/MachineLearning-Lecture01.pdf', 'page': 0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = text_splitter.split_documents(pages)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### context aware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VectorStore & Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    # PyPDFLoader(\"docs/MachineLearning-Lecture01.pdf\"),\n",
    "    # PyPDFLoader(\"docs/MachineLearning-Lecture01.pdf\"),\n",
    "    # PyPDFLoader(\"docs/MachineLearning-Lecture02.pdf\"),\n",
    "    # PyPDFLoader(\"docs/MachineLearning-Lecture03.pdf\")\n",
    "    PyPDFLoader(\"docs/Gadgeon.pdf\"),\n",
    "    PyPDFLoader(\"docs/doc.pdf\"),\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-M9CVthH53cZTlzWYQuk6Ug3B on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-M9CVthH53cZTlzWYQuk6Ug3B on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-M9CVthH53cZTlzWYQuk6Ug3B on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-M9CVthH53cZTlzWYQuk6Ug3B on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-M9CVthH53cZTlzWYQuk6Ug3B on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-M9CVthH53cZTlzWYQuk6Ug3B on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\"\n",
    "\n",
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9631973137440455\n",
      "0.771004645868524\n",
      "0.7596054193696385\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(embedding1, embedding2))\n",
    "print(np.dot(embedding1, embedding3))\n",
    "print(np.dot(embedding2, embedding3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'\n",
    "!rm -rf ./docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-M9CVthH53cZTlzWYQuk6Ug3B on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-M9CVthH53cZTlzWYQuk6Ug3B on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-M9CVthH53cZTlzWYQuk6Ug3B on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is does webcardio do?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "or\n",
      "any\n",
      "other\n",
      "buildings\n",
      "from\n",
      "a\n",
      "mobile\n",
      "or\n",
      "any\n",
      "internet\n",
      "accessible\n",
      "device\n",
      "from\n",
      "anywhere\n",
      "in\n",
      "the\n",
      "world.\n",
      "Gadgeon\n",
      "Medical\n",
      "Systems\n",
      "Pvt.\n",
      "Ltd\n",
      "a\n",
      "fully\n",
      "owned\n",
      "subsidiary\n",
      "of\n",
      "Gadgeon\n",
      "Smart\n",
      "Systems\n",
      "Private\n",
      "Limited,\n",
      "with\n",
      "a\n",
      "vision\n",
      "to\n",
      "be\n",
      "the\n",
      "leader\n",
      "in\n",
      "engineering\n",
      "a\n",
      "healthier\n",
      "future\n",
      "where\n",
      "digitally\n",
      "enabled,\n",
      "personalized,\n",
      "predictive,\n",
      "preventive,\n",
      "and\n",
      "participatory\n",
      "healthcare\n",
      "helps\n",
      "people\n",
      "live\n",
      "healthier\n",
      "and\n",
      "longer\n",
      "lives.\n",
      "The\n",
      "company's\n",
      "mission\n",
      "is\n",
      "to\n",
      "focus\n",
      "on\n",
      "commercializing\n",
      "innovative\n",
      "technologies\n",
      "to\n",
      "create\n",
      "clinical\n",
      "outcomes\n",
      "for\n",
      "the\n",
      "patients.\n",
      "Our\n",
      "flagship\n",
      "healthcare\n",
      "platform\n",
      "â€“\n",
      "WebCardio\n",
      "is\n",
      "a\n",
      "connected\n",
      "care\n",
      "platform\n",
      "that\n",
      "is\n",
      "already\n",
      "transforming\n",
      "the\n",
      "way\n",
      "Ambulatory\n",
      "Cardiac\n",
      "monitoring\n",
      "is\n",
      "delivered\n",
      "and\n",
      "has\n",
      "become\n",
      "the\n",
      "new\n",
      "normal\n",
      "among\n",
      "the\n",
      "leading\n",
      "cardiologists\n",
      "and\n",
      "neurologists\n",
      "in\n",
      "hospitals\n",
      "across\n",
      "India\n",
      "and\n",
      "abroad.\n",
      "Our\n",
      "Product\n",
      "engineering\n",
      "services\n",
      "use\n",
      "hardware,\n",
      "embedded,\n",
      "software,\n",
      "and\n",
      "IT\n",
      "solutions\n",
      "for\n",
      "faster\n",
      "design,\n",
      "development,\n",
      "and\n",
      "launching\n",
      "of\n",
      "products.\n",
      "Today,\n",
      "lack\n",
      "of\n",
      "the\n",
      "right\n",
      "domain\n",
      "experience\n",
      "or\n",
      "technical\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "or\n",
      "any\n",
      "other\n",
      "buildings\n",
      "from\n",
      "a\n",
      "mobile\n",
      "or\n",
      "any\n",
      "internet\n",
      "accessible\n",
      "device\n",
      "from\n",
      "anywhere\n",
      "in\n",
      "the\n",
      "world.\n",
      "Gadgeon\n",
      "Medical\n",
      "Systems\n",
      "Pvt.\n",
      "Ltd\n",
      "a\n",
      "fully\n",
      "owned\n",
      "subsidiary\n",
      "of\n",
      "Gadgeon\n",
      "Smart\n",
      "Systems\n",
      "Private\n",
      "Limited,\n",
      "with\n",
      "a\n",
      "vision\n",
      "to\n",
      "be\n",
      "the\n",
      "leader\n",
      "in\n",
      "engineering\n",
      "a\n",
      "healthier\n",
      "future\n",
      "where\n",
      "digitally\n",
      "enabled,\n",
      "personalized,\n",
      "predictive,\n",
      "preventive,\n",
      "and\n",
      "participatory\n",
      "healthcare\n",
      "helps\n",
      "people\n",
      "live\n",
      "healthier\n",
      "and\n",
      "longer\n",
      "lives.\n",
      "The\n",
      "company's\n",
      "mission\n",
      "is\n",
      "to\n",
      "focus\n",
      "on\n",
      "commercializing\n",
      "innovative\n",
      "technologies\n",
      "to\n",
      "create\n",
      "clinical\n",
      "outcomes\n",
      "for\n",
      "the\n",
      "patients.\n",
      "Our\n",
      "flagship\n",
      "healthcare\n",
      "platform\n",
      "â€“\n",
      "WebCardio\n",
      "is\n",
      "a\n",
      "connected\n",
      "care\n",
      "platform\n",
      "that\n",
      "is\n",
      "already\n",
      "transforming\n",
      "the\n",
      "way\n",
      "Ambulatory\n",
      "Cardiac\n",
      "monitoring\n",
      "is\n",
      "delivered\n",
      "and\n",
      "has\n",
      "become\n",
      "the\n",
      "new\n",
      "normal\n",
      "among\n",
      "the\n",
      "leading\n",
      "cardiologists\n",
      "and\n",
      "neurologists\n",
      "in\n",
      "hospitals\n",
      "across\n",
      "India\n",
      "and\n",
      "abroad.\n",
      "Our\n",
      "Product\n",
      "engineering\n",
      "services\n",
      "use\n",
      "hardware,\n",
      "embedded,\n",
      "software,\n",
      "and\n",
      "IT\n",
      "solutions\n",
      "for\n",
      "faster\n",
      "design,\n",
      "development,\n",
      "and\n",
      "launching\n",
      "of\n",
      "products.\n",
      "Today,\n",
      "lack\n",
      "of\n",
      "the\n",
      "right\n",
      "domain\n",
      "experience\n",
      "or\n",
      "technical\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "visit:\n",
      "www.gadgeonlifestyle.com\n",
      "Gadgeon\n",
      "Lifestyle\n",
      "webcardio\n",
      "Gadgeon\n",
      "Medical\n",
      "Systems\n",
      "Gadgeon\n",
      "Medical\n",
      "Systems\n",
      "Pvt.\n",
      "Ltd\n",
      "a\n",
      "fully\n",
      "owned\n",
      "subsidiary\n",
      "of\n",
      "Gadgeon\n",
      "Smart\n",
      "Systems\n",
      "Private\n",
      "Limited,\n",
      "with\n",
      "a\n",
      "vision\n",
      "to\n",
      "be\n",
      "the\n",
      "leader\n",
      "in\n",
      "engineering\n",
      "a\n",
      "healthier\n",
      "future\n",
      "where\n",
      "digitally\n",
      "enabled,\n",
      "personalized,\n",
      "predictive,\n",
      "preventive,\n",
      "and\n",
      "participatory\n",
      "healthcare\n",
      "helps\n",
      "people\n",
      "live\n",
      "healthier\n",
      "and\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"or\\nany\\nother\\nbuildings\\nfrom\\na\\nmobile\\nor\\nany\\ninternet\\naccessible\\ndevice\\nfrom\\nanywhere\\nin\\nthe\\nworld.\\nGadgeon\\nMedical\\nSystems\\nPvt.\\nLtd\\na\\nfully\\nowned\\nsubsidiary\\nof\\nGadgeon\\nSmart\\nSystems\\nPrivate\\nLimited,\\nwith\\na\\nvision\\nto\\nbe\\nthe\\nleader\\nin\\nengineering\\na\\nhealthier\\nfuture\\nwhere\\ndigitally\\nenabled,\\npersonalized,\\npredictive,\\npreventive,\\nand\\nparticipatory\\nhealthcare\\nhelps\\npeople\\nlive\\nhealthier\\nand\\nlonger\\nlives.\\nThe\\ncompany's\\nmission\\nis\\nto\\nfocus\\non\\ncommercializing\\ninnovative\\ntechnologies\\nto\\ncreate\\nclinical\\noutcomes\\nfor\\nthe\\npatients.\\nOur\\nflagship\\nhealthcare\\nplatform\\nâ€“\\nWebCardio\\nis\\na\\nconnected\\ncare\\nplatform\\nthat\\nis\\nalready\\ntransforming\\nthe\\nway\\nAmbulatory\\nCardiac\\nmonitoring\\nis\\ndelivered\\nand\\nhas\\nbecome\\nthe\\nnew\\nnormal\\namong\\nthe\\nleading\\ncardiologists\\nand\\nneurologists\\nin\\nhospitals\\nacross\\nIndia\\nand\\nabroad.\\nOur\\nProduct\\nengineering\\nservices\\nuse\\nhardware,\\nembedded,\\nsoftware,\\nand\\nIT\\nsolutions\\nfor\\nfaster\\ndesign,\\ndevelopment,\\nand\\nlaunching\\nof\\nproducts.\\nToday,\\nlack\\nof\\nthe\\nright\\ndomain\\nexperience\\nor\\ntechnical\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('chatbot': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2969fe213b494c140e7654907b96b79b533340b119a1d1a3595710311b1ce708"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
